---
title: "STATS 506 Problem Set 2"
author: "Lindsey Lin"
format: pdf
editor: visual
---

#### GitHub Repository Link: <https://github.com/ziyelinlin/STATS-506-Problem-Set-2.git>

```{r}
library(microbenchmark)
```

## Problem 1 – **Modified Random Walk**

Consider a 1-dimensional random walk with the following rules:

1.  Start at 0.
2.  At each step, move +1 or -1 with 50/50 probability.
3.  If +1 is chosen, 5% of the time move +10 instead.
4.  If -1 is chosen, 20% of the time move -3 instead.
5.  Repeat steps 2-4 for n times.

(Note that if the +10 is chosen, it’s not +1 then +10, it is just +10.)

Write a function to determine the end position of this random walk. The input and output should be:

-   Input: The number of steps

-   Output: The final position of the walk

We’re going to implement this in **different ways** and compare them.

a\. Implement the random walk in these three versions:

```{r}
input_check <- function(n) {
  if (length(n) != 1 | n <= 0 | n != as.integer(n)) {
    stop ("Input must be a positive integer.")
  }
  else return (n)
}
```

-   Version 1: using a loop.

    ```{r for_loop}
    #' random_walk_1: Loop-based modified random walk
    #' 
    #' Simulates the final position of a one-dimensional modified random walk.
    #' @param n Positive integer, number of steps in the walk.
    #' @param seed Optional integer. If provided, fixes the random 
    #'        number generator seed.
    #' @return An integer giving the final position after \code{n} steps.

    random_walk_1 <- function(n, seed = NULL) {
      n <- input_check(n)
      if (!is.null(seed)) set.seed(seed)
      
      position <- 0
      for (i in seq_len(n)) {
        step <- sample(c(-3, -1, 1, 10), 
                       size = 1, 
                       prob = c(0.10, 0.40, 0.475, 0.025)
                       )
        position <- position + step
      }
      
      return (position)
    }
    random_walk_1(10)
    ```

-   Version 2: using built-in R vectorized functions. (Using no loops.) (Hint: Does the order of steps matter?)

    ```{r built_in_vectorized_functions}
    #' random_walk_2: Vectorized modified random walk
    #'
    #' Simulates the final position of a one-dimensional modified 
    #' random walk using a fully vectorized approach.
    #' @param n Positive integer, number of steps in the walk.
    #' @param seed Optional integer. If provided, fixes the random 
    #'        number generator seed.
    #' @return An integer giving the final position after \code{n} steps.

    random_walk_2 <- function(n, seed = NULL) {
      n <- input_check(n)
      if (!is.null(seed)) set.seed(seed)
      
      steps <- sample(c(-3, -1, 1, 10), 
                      size = n, 
                      replace = TRUE, 
                      prob = c(0.1, 0.4, 0.475, 0.025)
                      )
      position <- sum(steps)
      
      return (position)
    }
    random_walk_2(10)
    ```

-   Version 3: Implement the random walk using one of the “`apply`” functions.

    ```{r apply_based}
    #' random_walk_3: Apply-based modified random walk
    #'
    #' Simulates the final position of a one-dimensional modified 
    #' random walk using the \code{sapply()} function to generate each step.
    #' @param n Positive integer, number of steps in the walk.
    #' @param seed Optional integer. If provided, fixes the random 
    #'        number generator seed.
    #' @return An integer giving the final position after \code{n} steps.

    random_walk_3 <- function(n, seed = NULL) {
      n <- input_check(n)
      if (!is.null(seed)) set.seed(seed)
      
      steps <- sapply(seq_len(n), 
                      function(x) sample(c(-3, -1, 1, 10), 
                                         size = 1, 
                                         prob = c(0.1, 0.4, 0.475, 0.025)
                                         )
                      )
      position <- sum(steps)
      
      return (position)
    }
    random_walk_3(10)
    ```

Demonstrate that all versions work by running the following:

```{r}
random_walk_1(10)
random_walk_2(10)
random_walk_3(10)
random_walk_1(1000)
random_walk_2(1000)
random_walk_3(1000)
```

b\. Demonstrate that the three versions **can give the same result**. Show this for both `n=10` and `n=1000`. (You will need to add a way to control the randomization.)

```{r}
# n = 10 
c(random_walk_1(10, seed = 506), 
  random_walk_2(10, seed = 506), 
  random_walk_3(10, seed = 506))

# n = 1000
c(random_walk_1(1000, seed = 123), 
  random_walk_2(1000, seed = 123), 
  random_walk_3(1000, seed = 123))
```

c\. Use the **`microbenchmark`** package to clearly demonstrate the speed of the implementations. Compare performance with a low input (1,000) and a large input (100,000). Discuss the results.

Answer:

The vectorized approach (`random_walk_2`) is the most efficient and scales best to large problem sizes. The loop (`random_walk_1`) and apply (`random_walk_3`) versions are much slower because they repeatedly call `sample()`. The results align with expectations in R that vectorization is usually the most efficient way to perform repetitive operations.

```{r}
n_small <- 1000
benchmark_small <- microbenchmark(
  random_walk_1(n_small),
  random_walk_2(n_small),
  random_walk_3(n_small),
  times = 10,
  unit = "ms"
)
benchmark_small
```

```{r}
n_large <- 100000
benchmark_large <- microbenchmark(
  random_walk_1(n_large),
  random_walk_2(n_large),
  random_walk_3(n_large),
  times = 10,
  unit = "ms"
)
benchmark_large
```

d\. What is the **probability** that the random walk ends at 0 if the number of steps is 10? 100? 1000? Defend your answers with evidence based upon a Monte Carlo simulation.

Answer:

I ran 10,000 independent simulations for each case. For each n, I estimated the probability of ending exactly at 0 as the proportion of simulations with final position = 0. The probabilities that the random walk ends at 0 I got are around 0.13 at n = 10, about 0.02 at n = 100, and about 0.005 at n = 1000.

As the number of steps increases, the variance of the walk increases, making the distribution of the final position spreads out. This makes it increasingly unlikely that the walk ends exactly at 0, which explains why the probability decreases sharply from about 13% at 10 steps to only about very small probability by 1000 steps.

```{r}
#' monte_carlo_simulator: Estimate probability of ending at 0
#'
#' Uses Monte Carlo simulation to estimate the probability that 
#' a modified random walk ends at position 0 after \code{n} steps.
#'
#' The function repeatedly calls \code{\link{random_walk_2}} to generate
#' independent random walks and calculates the proportion that end at 0.
#'
#' @param n Positive integer, number of steps in each random walk.
#' @param n_simulations Positive integer, number of independent 
#'        simulations to run. Defaults to 10,000.
#' @return A numeric value between 0 and 1 giving the estimated probability 
#'         that the walk ends at 0.

monte_carlo_simulator <- function(n, n_simulations = 10000) {
  results <- numeric(n_simulations)
  
  for (i in seq_len(n_simulations)) {
    results[i] <- random_walk_2(n)
  }
  
  prob_zero <- mean(results == 0) 
  return (prob_zero)
}

monte_carlo_simulator(10) 
monte_carlo_simulator(100)
monte_carlo_simulator(1000)
```

## **Problem 2 - Mean of Mixture of Distributions**

The number of cars passing an intersection is a classic example of a **Poisson distribution**. At a particular intersection, Poisson is an appropriate distribution **most of the time**, but during **rush hours** (hours of 8am and 5pm) the distribution is really **normally distributed with a much higher mean**.

Using a Monte Carlo simulation, estimate the average number of cars that pass an intersection per day under the following assumptions:

-   From midnight until 7 AM, the distribution of cars per hour is Poisson with mean 1.

-   From 9am to 4pm, the distribution of cars per hour is Poisson with mean 8.

-   From 6pm to 11pm, the distribution of cars per hour is Poisson with mean 12.

-   During rush hours (8am and 5pm), the distribution of cars per hour is Normal with mean 60 and variance 12

Accomplish this **without using any loops**.

(Hint: This can be done with extremely minimal code.)

Answer:

Based on a Monte Carlo simulation of 100,000 independent days, the estimated average number of cars that pass the intersection per day is about 264.

This aligns with the theoretical expected value: $\mathbb{E}[\text{total}] = 8 \cdot 1 + 1 \cdot 60 + 8 \cdot 8 + 1 \cdot 60 + 6 \cdot 12 = 264$ cars.

```{r}
cars_per_day <- function(seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  midnight_to_7am    <- rpois(8, lambda = 1)                # 7 hours
  rush_hour_morning  <- rnorm(1, mean = 60, sd = sqrt(12))  # 1 hour (8am)
  nine_to_four       <- rpois(8, lambda = 8)                # 8 hours
  rush_hour_evening  <- rnorm(1, mean = 60, sd = sqrt(12))  # 1 hour (5pm)
  six_to_eleven      <- rpois(6, lambda = 12)               # 6 hours
  
  total_cars <- sum(midnight_to_7am,
                    rush_hour_morning,
                    nine_to_four,
                    rush_hour_evening,
                    six_to_eleven)
  return(total_cars)
}

totals <- replicate(100000, cars_per_day())
mean(totals)
```

```{r}
cars_per_day_vec <- function(days = 100000, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  # Simulate all hours at once for all days
  midnight_to_7am   <- matrix(rpois(8 * days,  lambda = 1),  nrow = 8)
  rush_hour_morning <- rnorm(days,  mean = 60, sd = sqrt(12))
  nine_to_four      <- matrix(rpois(8 * days,  lambda = 8),  nrow = 8)
  rush_hour_evening <- rnorm(days,  mean = 60, sd = sqrt(12))
  six_to_eleven     <- matrix(rpois(6 * days,  lambda = 12), nrow = 6)

  # Totals for each day = column sums across all blocks
  totals <- colSums(midnight_to_7am) +
            rush_hour_morning +
            colSums(nine_to_four) +
            rush_hour_evening +
            colSums(six_to_eleven)
  
  # Monte Carlo estimate of expected daily cars
  return (mean(totals))  
}
cars_per_day_vec(days = 100000)
```

## **Problem 3 - Linear Regression**
